{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huymac/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Input, concatenate\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import ast\n",
    "import operator\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_dictionary = {'San Francisco': 94107,\n",
    "                 'Redwood City': 94063,\n",
    "                 'Palo Alto': 94301,\n",
    "                 'Mountain View': 94041,\n",
    "                 'San Jose': 95113}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Example of station id 5:', [37.331415, -121.8932, 19, 95113])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"read station_data.csv file\n",
    "\n",
    "returns\n",
    "    station_dic {id: [lat, long, dock count,zip]}\n",
    "    \n",
    "\"\"\"\n",
    "station_dic = {}\n",
    "with open(\"data/station_data.csv\",\"r\") as station_file:\n",
    "    station_file.readline() #skip the first line\n",
    "    for line in station_file:\n",
    "        line = line.replace(\"\\r\\n\",\"\")\n",
    "        fields = line.split(\",\")\n",
    "        station_dic[int(fields[0])] = []\n",
    "        for i in range(2,5):\n",
    "            station_dic[int(fields[0])].append(ast.literal_eval(fields[i]))\n",
    "        \n",
    "        station_dic[int(fields[0])].append(zip_dictionary[fields[5]])\n",
    "print (\"Example of station id 5:\", station_dic[5])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Example of weather at (17/09/2014,94107):', [77, 69, 61, 64, 58, 55, 84, 67, 50, 29.83, 29.8, 29.75, 10, 10, 9, 21, 9, 29, 0.001, 5, 0, 1, 0, 0, 0, 267])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"read weather_data.csv file\n",
    "\n",
    "returns\n",
    "    weather_dic {(date, zip): [Max Temperature, Mean Temperature, ...]}\n",
    "\"\"\"\n",
    "\n",
    "weather_dic = {}\n",
    "events_dic = {'': [1,0,0,0,0], 'Rain': [0,1,0,0,0], 'Fog-Rain': [0,0,1,0,0], 'Rain-Thunderstorm': [0,0,0,1,0], 'Fog': [0,0,0,0,1]}\n",
    "with open(\"data/weather_data.csv\",\"r\") as weather_file:\n",
    "    weather_file.readline() #skip the first line\n",
    "    for line in weather_file:\n",
    "        line = line.replace(\"\\r\\n\",\"\")\n",
    "        fields = line.split(\",\")\n",
    "        weather_dic[(fields[0],int(fields[-1]))]= []\n",
    "        for i in range(1,len(fields)-1):\n",
    "            if i == (len(fields)-3):\n",
    "                weather_dic[(fields[0],int(fields[-1]))] += events_dic[fields[i]]\n",
    "            elif fields[i]==\"\":\n",
    "                weather_dic[(fields[0],int(fields[-1]))].append(0)\n",
    "            else:\n",
    "                weather_dic[(fields[0],int(fields[-1]))].append(ast.literal_eval(fields[i]))\n",
    "print (\"Example of weather at (17/09/2014,94107):\",weather_dic[(\"17/09/2014\",94107)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Example of net rate dictionary:', {('31/03/2015', 9, 11): 1, ('20/07/2015', 32, 6): -1, ('27/04/2015', 4, 13): 1, ('02/07/2015', 74, 14): 0, ('15/07/2015', 90, 7): -1})\n",
      "('Example of top route dictionary:', {2: [(4, 2446), (6, 1301), (11, 1129), (7, 790), (13, 653), (84, 645), (9, 611), (5, 575), (10, 518), (3, 491), (16, 229), (8, 215), (12, 206), (2, 153), (80, 25), (14, 23), (28, 2)], 3: [(2, 491), (3, 377), (10, 133), (84, 122), (6, 100), (11, 69), (12, 67), (4, 63), (7, 59), (9, 43), (5, 39), (14, 39), (16, 35), (8, 19), (80, 14), (13, 9), (28, 2), (29, 1)], 4: [(2, 2446), (14, 510), (12, 305), (4, 209), (7, 65), (3, 63), (8, 37), (11, 30), (5, 29), (10, 29), (6, 27), (16, 26), (9, 21), (84, 17), (13, 13), (80, 8)], 5: [(2, 575), (12, 60), (5, 57), (7, 56), (6, 42), (3, 39), (10, 32), (4, 29), (11, 29), (13, 25), (9, 24), (8, 23), (16, 17), (14, 15), (84, 15), (80, 13)], 6: [(2, 1301), (9, 247), (84, 218), (80, 202), (13, 176), (6, 171), (14, 137), (3, 100), (8, 83), (10, 80), (7, 77), (11, 69), (5, 42), (12, 42), (16, 40), (4, 27)]})\n"
     ]
    }
   ],
   "source": [
    "\"\"\"read trip_data.csv file\n",
    "\n",
    "returns\n",
    "    trip_started_dictionary {(date, station id, hour): count}\n",
    "    trip_ended_dictionary {(date, station id, hour): count}\n",
    "    net_rate_dictionary {(date, station id, hour): net rate}\n",
    "    top_route_dictionary {station id: [station id1, station id2,...]}\n",
    "    route_dictionary {(station1,station2):count}\n",
    "\"\"\"\n",
    "trip_started_dictionary = {}\n",
    "trip_ended_dictionary = {}\n",
    "net_rate_dictionary = {}\n",
    "top_route_dictionary = {}\n",
    "route_dictionary = {}\n",
    "date_list = []\n",
    "type_dic = {\"Subscriber\":0, \"Customer\":1}\n",
    "count = 0\n",
    "with open(\"data/trip_data.csv\",\"r\") as trip_file:\n",
    "    trip_file.readline() #skip the first line\n",
    "    for line in trip_file:\n",
    "        line = line.replace(\"\\n\",\"\").replace(\"\\r\",\"\")\n",
    "        fields = line.split(\",\")\n",
    "        start_date = fields[1].split(\" \")[0]\n",
    "        start_station = int(fields[2])\n",
    "        start_hour = int(fields[1].split(\" \")[1].split(\":\")[0])\n",
    "        end_date = fields[3].split(\" \")[0]\n",
    "        end_station =  int(fields[4])\n",
    "        end_hour = int(fields[3].split(\" \")[1].split(\":\")[0])\n",
    "        sub_type = type_dic[fields[-1]]\n",
    "\n",
    "        #print (date,start_station,start_hour,end_station,end_hour,sub_type)\n",
    "        if (start_date,start_station,start_hour) in trip_started_dictionary:\n",
    "            trip_started_dictionary[(start_date,start_station,start_hour)] +=1\n",
    "        else:\n",
    "            trip_started_dictionary[(start_date,start_station,start_hour)] = 1\n",
    "        if (start_date,start_station,start_hour) not in trip_ended_dictionary:\n",
    "            trip_ended_dictionary[(start_date,start_station,start_hour)] = 0\n",
    "        if (end_date,end_station,end_hour) in trip_ended_dictionary:\n",
    "            trip_ended_dictionary[(end_date,end_station,end_hour)] +=1\n",
    "        else:\n",
    "            trip_ended_dictionary[(end_date,end_station,end_hour)] =1\n",
    "            \n",
    "        if (end_date,end_station,end_hour) not in trip_started_dictionary:\n",
    "            trip_started_dictionary[(end_date,end_station,end_hour)] = 0\n",
    "        if (start_station,end_station) not in route_dictionary:\n",
    "            route_dictionary[(start_station,end_station)] = 1\n",
    "            route_dictionary[(end_station,start_station)] = 1\n",
    "        else:\n",
    "            route_dictionary[(start_station,end_station)] += 1\n",
    "            route_dictionary[(end_station,start_station)] += 1\n",
    "        \n",
    "        \n",
    "for station1 in station_dic:\n",
    "    station1_route = {}\n",
    "    for station2 in station_dic:\n",
    "        if (station1,station2) in route_dictionary:\n",
    "            station1_route[station2] = route_dictionary[(station1,station2)]\n",
    "    station1_route = sorted(station1_route.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    top_route_dictionary[station1] = station1_route \n",
    "\n",
    "     \n",
    "\n",
    "for key in trip_ended_dictionary:\n",
    "    net_rate_dictionary[key] = trip_ended_dictionary[key] - trip_started_dictionary[key]\n",
    "print(\"Example of net rate dictionary:\", dict(list(net_rate_dictionary.items())[0:5]))\n",
    "print(\"Example of top route dictionary:\", dict(list(top_route_dictionary.items())[0:5]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Input: station_data_array, conntectedStation_data_array and Output y_data preprocessing\"\"\"\n",
    "\n",
    "weekday_dic = {\"Monday\":[1,0,0,0,0,0,0], \"Tuesday\":[0,1,0,0,0,0,0], \"Wednesday\":[0,0,1,0,0,0,0],\n",
    "              \"Thursday\":[0,0,0,1,0,0,0], \"Friday\":[0,0,0,0,1,0,0], \"Saturday\":[0,0,0,0,0,1,0], \"Sunday\":[0,0,0,0,0,0,1]}\n",
    "season_dic = {\"01\":[1,0,0,0],\"02\":[1,0,0,0],\"03\":[1,0,0,0],\"04\":[0,1,0,0],\"05\":[0,1,0,0],\"06\":[0,1,0,0],\"07\":[0,0,1,0],\n",
    "             \"08\":[0,0,1,0],\"09\":[0,0,1,0],\"10\":[0,0,0,1],\"11\":[0,0,0,1],\"12\":[0,0,0,1]}\n",
    "station_data_array = []\n",
    "conntectedStation_data_array = []\n",
    "y_data = []\n",
    "full_data = []\n",
    "for item in net_rate_dictionary:\n",
    "    date, station_id, hour = item\n",
    "    label = net_rate_dictionary[item]\n",
    "    lat, longtitue, dockcount,zip_code  = station_dic[station_id]\n",
    "    weather = weather_dic[(date,zip_code)]\n",
    "    dd,mm,yy = date.split(\"/\")\n",
    "    weekday = weekday_dic[datetime.date(int(yy),int(mm),int(dd)).strftime(\"%A\")]\n",
    "    season = season_dic[mm]\n",
    "    hour_category = [0]*24\n",
    "    hour_category[hour] = 1\n",
    "    station_data = [lat,longtitue,dockcount]+weekday+season+weather+hour_category\n",
    "    #Station infor\n",
    "    station_data_array.append(station_data)\n",
    "    #Top 5 connected station in previous three hours\n",
    "    connected_stations = top_route_dictionary[station_id][0:5]\n",
    "    connected_station_data = []\n",
    "    for pre_hour in range(hour-3,hour):\n",
    "        connected_station_data_perhour = []\n",
    "        if pre_hour < 0:\n",
    "            pre_hour += 24\n",
    "            current_date = (datetime.date(int(yy),int(mm),int(dd)) - datetime.timedelta(1)).strftime(\"%d/%m/%Y\")\n",
    "        else:\n",
    "            current_date = date\n",
    "        for connected_station_id,value in connected_stations:\n",
    "            if (current_date,connected_station_id,pre_hour) not in net_rate_dictionary:\n",
    "                start = 0\n",
    "                end = 0\n",
    "                net = 0\n",
    "            else:\n",
    "                start = trip_started_dictionary[(current_date,connected_station_id,pre_hour)]\n",
    "                end = trip_ended_dictionary[(current_date,connected_station_id,pre_hour)]\n",
    "                net = net_rate_dictionary[(current_date,connected_station_id,pre_hour)]\n",
    "            connected_station_data_perhour.append(start)\n",
    "            connected_station_data_perhour.append(end)\n",
    "            connected_station_data_perhour.append(net)\n",
    "        #append infor of the current station\n",
    "        if (current_date,station_id,pre_hour) not in net_rate_dictionary:\n",
    "            start = 0\n",
    "            end = 0\n",
    "            net = 0\n",
    "        else:\n",
    "            start = trip_started_dictionary[(current_date,station_id,pre_hour)]\n",
    "            end = trip_ended_dictionary[(current_date,station_id,pre_hour)]\n",
    "            net = net_rate_dictionary[(current_date,station_id,pre_hour)]\n",
    "        connected_station_data_perhour.append(start)\n",
    "        connected_station_data_perhour.append(end)\n",
    "        connected_station_data_perhour.append(net)\n",
    "        \n",
    "        connected_station_data.append(connected_station_data_perhour)\n",
    "    conntectedStation_data_array.append(connected_station_data)\n",
    "    y_data.append([label])\n",
    "    full_data.append([date,station_id,hour,weather])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huymac/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Normalize data\"\"\"\n",
    "station_data_scaler = MinMaxScaler()\n",
    "station_data_scaler.fit(station_data_array)\n",
    "station_data_norm_array = station_data_scaler.transform(station_data_array)\n",
    "\n",
    "\n",
    "y_data_scaler = MinMaxScaler(feature_range=(-20,20))\n",
    "y_data_scaler.fit(y_data)\n",
    "y_data_norm_array = y_data_scaler.transform(y_data)\n",
    "conntectedStation_data_array = np.array(conntectedStation_data_array)\n",
    "conntectedStation_data_array = conntectedStation_data_array.reshape(-1,54)\n",
    "\n",
    "conntectedStation_data_scaler = MinMaxScaler()\n",
    "conntectedStation_data_scaler.fit(conntectedStation_data_array)\n",
    "conntectedStation_data_array = conntectedStation_data_scaler.transform(conntectedStation_data_array)\n",
    "\n",
    "conntectedStation_data_array = conntectedStation_data_array.reshape(-1,3,18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of station data train:', (126184, 64))\n",
      "('Shape of Connected stations data train:', (126184, 3, 18))\n",
      "('Shape of output train:', (126184, 1))\n",
      "('Size of train:', 126184)\n",
      "('Size of test:', 36107)\n",
      "('Size of dev:', 35865)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Split data into train/dev/test\"\"\"\n",
    "station_data_norm_array = np.array(station_data_norm_array)\n",
    "y_data_norm_array = np.array(y_data_norm_array)\n",
    "\n",
    "\n",
    "station_data_norm_array_train = []\n",
    "station_data_norm_array_dev = []\n",
    "station_data_norm_array_test = []\n",
    "\n",
    "conntectedStation_data_array_train = []\n",
    "conntectedStation_data_array_dev = []\n",
    "conntectedStation_data_array_test = []\n",
    "\n",
    "y_data_norm_array_train = []\n",
    "y_data_norm_array_dev = []\n",
    "y_data_norm_array_test = []\n",
    "\n",
    "full_data_test = []\n",
    "\n",
    "#Split data for train/dev/test 60/20/20\n",
    "for i in range(0,len(y_data_norm_array)):\n",
    "    randnum = random.randint(0,10)\n",
    "    if randnum <= 6:\n",
    "        station_data_norm_array_train.append(station_data_norm_array[i])\n",
    "        conntectedStation_data_array_train.append(conntectedStation_data_array[i])\n",
    "        y_data_norm_array_train.append(y_data_norm_array[i])\n",
    "    elif randnum >6 and randnum <=8:\n",
    "        station_data_norm_array_dev.append(station_data_norm_array[i])\n",
    "        conntectedStation_data_array_dev.append(conntectedStation_data_array[i])\n",
    "        y_data_norm_array_dev.append(y_data_norm_array[i])\n",
    "    else:\n",
    "        station_data_norm_array_test.append(station_data_norm_array[i])\n",
    "        conntectedStation_data_array_test.append(conntectedStation_data_array[i])\n",
    "        y_data_norm_array_test.append(y_data_norm_array[i])\n",
    "        full_data_test.append(full_data[i])\n",
    "        \n",
    "station_data_norm_array_train = np.array(station_data_norm_array_train)\n",
    "station_data_norm_array_dev = np.array(station_data_norm_array_dev)\n",
    "station_data_norm_array_test = np.array(station_data_norm_array_test)\n",
    "\n",
    "conntectedStation_data_array_train = np.array(conntectedStation_data_array_train)\n",
    "conntectedStation_data_array_dev = np.array(conntectedStation_data_array_dev)\n",
    "conntectedStation_data_array_test = np.array(conntectedStation_data_array_test)\n",
    "\n",
    "y_data_norm_array_train = np.array(y_data_norm_array_train)\n",
    "y_data_norm_array_dev = np.array(y_data_norm_array_dev)\n",
    "y_data_norm_array_test = np.array(y_data_norm_array_test)\n",
    "\n",
    "print (\"Shape of station data train:\",station_data_norm_array_train.shape)\n",
    "print (\"Shape of Connected stations data train:\",conntectedStation_data_array_train.shape)\n",
    "print (\"Shape of output train:\",y_data_norm_array_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "print (\"Size of train:\",len(y_data_norm_array_train))\n",
    "print (\"Size of test:\",len(y_data_norm_array_test))\n",
    "print (\"Size of dev:\",len(y_data_norm_array_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0815 07:19:04.358596 4698949056 deprecation_wrapper.py:119] From /Users/huymac/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0815 07:19:04.385994 4698949056 deprecation_wrapper.py:119] From /Users/huymac/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0815 07:19:04.401127 4698949056 deprecation_wrapper.py:119] From /Users/huymac/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "/Users/huymac/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  del sys.path[0]\n",
      "W0815 07:19:04.691793 4698949056 deprecation_wrapper.py:119] From /Users/huymac/anaconda2/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "/Users/huymac/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:20: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "W0815 07:19:04.945854 4698949056 deprecation.py:323] From /Users/huymac/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0815 07:19:05.872499 4698949056 deprecation_wrapper.py:119] From /Users/huymac/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0815 07:19:05.889497 4698949056 deprecation_wrapper.py:119] From /Users/huymac/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 126184 samples, validate on 35865 samples\n",
      "Epoch 1/100\n",
      "126184/126184 [==============================] - 9s 73us/step - loss: 1.6365 - val_loss: 1.5677\n",
      "Epoch 2/100\n",
      "126184/126184 [==============================] - 10s 78us/step - loss: 1.4768 - val_loss: 1.5037\n",
      "Epoch 3/100\n",
      "126184/126184 [==============================] - 9s 69us/step - loss: 1.4138 - val_loss: 1.4276\n",
      "Epoch 4/100\n",
      "126184/126184 [==============================] - 8s 60us/step - loss: 1.3912 - val_loss: 1.4296\n",
      "Epoch 5/100\n",
      "126184/126184 [==============================] - 8s 62us/step - loss: 1.3704 - val_loss: 1.3960\n",
      "Epoch 6/100\n",
      "126184/126184 [==============================] - 8s 64us/step - loss: 1.3516 - val_loss: 1.4519\n",
      "Epoch 7/100\n",
      "126184/126184 [==============================] - 8s 61us/step - loss: 1.3295 - val_loss: 1.3400\n",
      "Epoch 8/100\n",
      "126184/126184 [==============================] - 8s 63us/step - loss: 1.3124 - val_loss: 1.3918\n",
      "Epoch 9/100\n",
      "126184/126184 [==============================] - 8s 60us/step - loss: 1.2960 - val_loss: 1.3035\n",
      "Epoch 10/100\n",
      "126184/126184 [==============================] - 8s 62us/step - loss: 1.2796 - val_loss: 1.2860\n",
      "Epoch 11/100\n",
      "126184/126184 [==============================] - 8s 65us/step - loss: 1.2658 - val_loss: 1.2737\n",
      "Epoch 12/100\n",
      "126184/126184 [==============================] - 8s 63us/step - loss: 1.2504 - val_loss: 1.2942\n",
      "Epoch 13/100\n",
      "126184/126184 [==============================] - 9s 67us/step - loss: 1.2371 - val_loss: 1.2488\n",
      "Epoch 14/100\n",
      "126184/126184 [==============================] - 7s 59us/step - loss: 1.2249 - val_loss: 1.2901\n",
      "Epoch 15/100\n",
      "126184/126184 [==============================] - 8s 59us/step - loss: 1.2139 - val_loss: 1.2278\n",
      "Epoch 16/100\n",
      "126184/126184 [==============================] - 8s 60us/step - loss: 1.2054 - val_loss: 1.2325\n",
      "Epoch 17/100\n",
      "126184/126184 [==============================] - 8s 60us/step - loss: 1.1942 - val_loss: 1.2249\n",
      "Epoch 18/100\n",
      "126184/126184 [==============================] - 8s 65us/step - loss: 1.1874 - val_loss: 1.2073\n",
      "Epoch 19/100\n",
      "126184/126184 [==============================] - 8s 66us/step - loss: 1.1780 - val_loss: 1.2117\n",
      "Epoch 20/100\n",
      "126184/126184 [==============================] - 8s 66us/step - loss: 1.1695 - val_loss: 1.1824\n",
      "Epoch 21/100\n",
      "126184/126184 [==============================] - 8s 61us/step - loss: 1.1639 - val_loss: 1.1857\n",
      "Epoch 22/100\n",
      "126184/126184 [==============================] - 8s 62us/step - loss: 1.1567 - val_loss: 1.1836\n",
      "Epoch 23/100\n",
      "126184/126184 [==============================] - 8s 62us/step - loss: 1.1506 - val_loss: 1.1713\n",
      "Epoch 24/100\n",
      "126184/126184 [==============================] - 8s 65us/step - loss: 1.1439 - val_loss: 1.1487\n",
      "Epoch 25/100\n",
      "126184/126184 [==============================] - 7s 58us/step - loss: 1.1382 - val_loss: 1.1680\n",
      "Epoch 26/100\n",
      "126184/126184 [==============================] - 8s 66us/step - loss: 1.1324 - val_loss: 1.1528\n",
      "Epoch 27/100\n",
      "126184/126184 [==============================] - 10s 83us/step - loss: 1.1224 - val_loss: 1.1485\n",
      "Epoch 28/100\n",
      "126184/126184 [==============================] - 9s 71us/step - loss: 1.1222 - val_loss: 1.1812\n",
      "Epoch 29/100\n",
      "126184/126184 [==============================] - 8s 67us/step - loss: 1.1147 - val_loss: 1.1512\n",
      "Epoch 30/100\n",
      "126184/126184 [==============================] - 9s 70us/step - loss: 1.1116 - val_loss: 1.1417\n",
      "Epoch 31/100\n",
      "126184/126184 [==============================] - 8s 66us/step - loss: 1.1069 - val_loss: 1.1383\n",
      "Epoch 32/100\n",
      "126184/126184 [==============================] - 9s 73us/step - loss: 1.1018 - val_loss: 1.1491\n",
      "Epoch 33/100\n",
      "126184/126184 [==============================] - 9s 70us/step - loss: 1.0990 - val_loss: 1.1504\n",
      "Epoch 34/100\n",
      "126184/126184 [==============================] - 8s 60us/step - loss: 1.0957 - val_loss: 1.1422\n",
      "Epoch 35/100\n",
      "126184/126184 [==============================] - 8s 61us/step - loss: 1.0904 - val_loss: 1.1157\n",
      "Epoch 36/100\n",
      "126184/126184 [==============================] - 10s 77us/step - loss: 1.0856 - val_loss: 1.1197\n",
      "Epoch 37/100\n",
      "126184/126184 [==============================] - 10s 76us/step - loss: 1.0839 - val_loss: 1.1060\n",
      "Epoch 38/100\n",
      "126184/126184 [==============================] - 9s 70us/step - loss: 1.0786 - val_loss: 1.1387\n",
      "Epoch 39/100\n",
      "126184/126184 [==============================] - 8s 66us/step - loss: 1.0751 - val_loss: 1.1206\n",
      "Epoch 40/100\n",
      "126184/126184 [==============================] - 8s 63us/step - loss: 1.0713 - val_loss: 1.1056\n",
      "Epoch 41/100\n",
      "126184/126184 [==============================] - 9s 68us/step - loss: 1.0679 - val_loss: 1.1056\n",
      "Epoch 42/100\n",
      "126184/126184 [==============================] - 10s 80us/step - loss: 1.0625 - val_loss: 1.1027\n",
      "Epoch 43/100\n",
      "126184/126184 [==============================] - 8s 60us/step - loss: 1.0612 - val_loss: 1.1103\n",
      "Epoch 44/100\n",
      "126184/126184 [==============================] - 8s 64us/step - loss: 1.0600 - val_loss: 1.1013\n",
      "Epoch 45/100\n",
      "126184/126184 [==============================] - 10s 77us/step - loss: 1.0552 - val_loss: 1.0930\n",
      "Epoch 46/100\n",
      "126184/126184 [==============================] - 8s 65us/step - loss: 1.0528 - val_loss: 1.1008\n",
      "Epoch 47/100\n",
      "126184/126184 [==============================] - 8s 66us/step - loss: 1.0485 - val_loss: 1.0957\n",
      "Epoch 48/100\n",
      "126184/126184 [==============================] - 8s 61us/step - loss: 1.0487 - val_loss: 1.0996\n",
      "Epoch 49/100\n",
      "126184/126184 [==============================] - 8s 63us/step - loss: 1.0435 - val_loss: 1.0954\n",
      "Epoch 50/100\n",
      "126184/126184 [==============================] - 9s 70us/step - loss: 1.0415 - val_loss: 1.1007\n",
      "Epoch 51/100\n",
      "126184/126184 [==============================] - 9s 68us/step - loss: 1.0385 - val_loss: 1.1026\n",
      "Epoch 52/100\n",
      "126184/126184 [==============================] - 8s 65us/step - loss: 1.0360 - val_loss: 1.1012\n",
      "Epoch 53/100\n",
      "126184/126184 [==============================] - 9s 71us/step - loss: 1.0341 - val_loss: 1.0890\n",
      "Epoch 54/100\n",
      "126184/126184 [==============================] - 8s 64us/step - loss: 1.0310 - val_loss: 1.1231\n",
      "Epoch 55/100\n",
      "126184/126184 [==============================] - 8s 65us/step - loss: 1.0279 - val_loss: 1.1314\n",
      "Epoch 56/100\n",
      "126184/126184 [==============================] - 8s 63us/step - loss: 1.0259 - val_loss: 1.0854\n",
      "Epoch 57/100\n",
      "126184/126184 [==============================] - 9s 69us/step - loss: 1.0231 - val_loss: 1.0922\n",
      "Epoch 58/100\n",
      "126184/126184 [==============================] - 8s 64us/step - loss: 1.0216 - val_loss: 1.0872\n",
      "Epoch 59/100\n",
      "126184/126184 [==============================] - 8s 65us/step - loss: 1.0179 - val_loss: 1.0825\n",
      "Epoch 60/100\n",
      "126184/126184 [==============================] - 8s 65us/step - loss: 1.0157 - val_loss: 1.0930\n",
      "Epoch 61/100\n",
      "126184/126184 [==============================] - 9s 68us/step - loss: 1.0125 - val_loss: 1.0786\n",
      "Epoch 62/100\n",
      "126184/126184 [==============================] - 8s 63us/step - loss: 1.0132 - val_loss: 1.0641\n",
      "Epoch 63/100\n",
      "126184/126184 [==============================] - 9s 71us/step - loss: 1.0069 - val_loss: 1.0711\n",
      "Epoch 64/100\n",
      "126184/126184 [==============================] - 11s 90us/step - loss: 1.0072 - val_loss: 1.0734\n",
      "Epoch 65/100\n",
      "126184/126184 [==============================] - 10s 76us/step - loss: 1.0039 - val_loss: 1.0796\n",
      "Epoch 66/100\n",
      "126184/126184 [==============================] - 10s 76us/step - loss: 1.0028 - val_loss: 1.0699\n",
      "Epoch 67/100\n",
      "126184/126184 [==============================] - 9s 69us/step - loss: 1.0006 - val_loss: 1.0862\n",
      "Epoch 68/100\n",
      "126184/126184 [==============================] - 9s 68us/step - loss: 0.9969 - val_loss: 1.0723\n",
      "Epoch 69/100\n",
      "126184/126184 [==============================] - 8s 66us/step - loss: 0.9959 - val_loss: 1.0650\n",
      "Epoch 70/100\n",
      "126184/126184 [==============================] - 8s 67us/step - loss: 0.9918 - val_loss: 1.0784\n",
      "Epoch 71/100\n",
      "126184/126184 [==============================] - 9s 70us/step - loss: 0.9909 - val_loss: 1.0759\n",
      "Epoch 72/100\n",
      "126184/126184 [==============================] - 9s 68us/step - loss: 0.9875 - val_loss: 1.0646\n",
      "Epoch 73/100\n",
      "126184/126184 [==============================] - 8s 63us/step - loss: 0.9859 - val_loss: 1.1098\n",
      "Epoch 74/100\n",
      "126184/126184 [==============================] - 8s 67us/step - loss: 0.9847 - val_loss: 1.0680\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126184/126184 [==============================] - 8s 64us/step - loss: 0.9822 - val_loss: 1.0792\n",
      "Epoch 76/100\n",
      "126184/126184 [==============================] - 8s 64us/step - loss: 0.9802 - val_loss: 1.0716\n",
      "Epoch 77/100\n",
      "126184/126184 [==============================] - 8s 65us/step - loss: 0.9782 - val_loss: 1.0583\n",
      "Epoch 78/100\n",
      "126184/126184 [==============================] - 8s 64us/step - loss: 0.9770 - val_loss: 1.0698\n",
      "Epoch 79/100\n",
      "126184/126184 [==============================] - 8s 63us/step - loss: 0.9755 - val_loss: 1.0613\n",
      "Epoch 80/100\n",
      "126184/126184 [==============================] - 9s 70us/step - loss: 0.9733 - val_loss: 1.0667\n",
      "Epoch 81/100\n",
      "126184/126184 [==============================] - 9s 71us/step - loss: 0.9703 - val_loss: 1.0762\n",
      "Epoch 82/100\n",
      "126184/126184 [==============================] - 8s 64us/step - loss: 0.9685 - val_loss: 1.0649\n",
      "Epoch 83/100\n",
      "126184/126184 [==============================] - 8s 60us/step - loss: 0.9659 - val_loss: 1.0669\n",
      "Epoch 84/100\n",
      "126184/126184 [==============================] - 8s 60us/step - loss: 0.9656 - val_loss: 1.0737\n",
      "Epoch 85/100\n",
      "126184/126184 [==============================] - 8s 62us/step - loss: 0.9612 - val_loss: 1.0607\n",
      "Epoch 86/100\n",
      "126184/126184 [==============================] - 8s 61us/step - loss: 0.9608 - val_loss: 1.0899\n",
      "Epoch 87/100\n",
      "126184/126184 [==============================] - 8s 61us/step - loss: 0.9576 - val_loss: 1.0645\n",
      "Epoch 88/100\n",
      "126184/126184 [==============================] - 8s 60us/step - loss: 0.9571 - val_loss: 1.0754\n",
      "Epoch 89/100\n",
      "126184/126184 [==============================] - 8s 62us/step - loss: 0.9560 - val_loss: 1.0672\n",
      "Epoch 90/100\n",
      "126184/126184 [==============================] - 8s 61us/step - loss: 0.9517 - val_loss: 1.0720\n",
      "Epoch 91/100\n",
      "126184/126184 [==============================] - 8s 60us/step - loss: 0.9503 - val_loss: 1.0782\n",
      "Epoch 92/100\n",
      "126184/126184 [==============================] - 8s 60us/step - loss: 0.9472 - val_loss: 1.0751\n",
      "Epoch 93/100\n",
      "126184/126184 [==============================] - 8s 60us/step - loss: 0.9467 - val_loss: 1.0719\n",
      "Epoch 94/100\n",
      "126184/126184 [==============================] - 8s 61us/step - loss: 0.9442 - val_loss: 1.0673\n",
      "Epoch 95/100\n",
      "126184/126184 [==============================] - 8s 62us/step - loss: 0.9437 - val_loss: 1.0715\n",
      "Epoch 96/100\n",
      "126184/126184 [==============================] - 8s 66us/step - loss: 0.9399 - val_loss: 1.0713\n",
      "Epoch 97/100\n",
      "126184/126184 [==============================] - 9s 68us/step - loss: 0.9390 - val_loss: 1.0750\n",
      "Epoch 98/100\n",
      "126184/126184 [==============================] - 10s 77us/step - loss: 0.9381 - val_loss: 1.0753\n",
      "Epoch 99/100\n",
      "126184/126184 [==============================] - 11s 85us/step - loss: 0.9361 - val_loss: 1.0806\n",
      "Epoch 100/100\n",
      "126184/126184 [==============================] - 11s 90us/step - loss: 0.9342 - val_loss: 1.0832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a38d4f250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Build model\"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "input_station_info_layer = Input(shape=(64,),dtype='float32',name=\"station_info_input\")\n",
    "input_connected_station_info_layer = Input(shape=(3,18),dtype='float32',name=\"connected_station_info_input\")\n",
    "\n",
    "hidden_lstm = LSTM(64)(input_connected_station_info_layer)\n",
    "hidden_dense = Dense(32,activation=\"sigmoid\")(input_station_info_layer)\n",
    "\n",
    "merge_layer = concatenate([hidden_lstm,hidden_dense],axis=1)\n",
    "out_layer = Dense(1,activation=\"linear\")(merge_layer)\n",
    "\n",
    "model = Model(input=[input_station_info_layer,input_connected_station_info_layer], output=[out_layer])\n",
    "adadelta = Adadelta(lr=1.0, rho=0.95, epsilon=1e-06)\n",
    "checkpoint = ModelCheckpoint(\"best.hdf5\",monitor=\"val_loss\",mode=\"min\", save_best_only=True)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=adadelta)\n",
    "\n",
    "model.fit([station_data_norm_array_train,conntectedStation_data_array_train],y_data_norm_array_train,\n",
    "         batch_size=100,nb_epoch=100, callbacks=[checkpoint],\n",
    "         validation_data=([station_data_norm_array_dev,conntectedStation_data_array_dev],y_data_norm_array_dev))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean squared error on test set:', 5.195668429944332)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Performance analysis\"\"\"\n",
    "model.load_weights(\"best.hdf5\")\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=adadelta)\n",
    "\n",
    "y_predict_norm = model.predict([station_data_norm_array_test,conntectedStation_data_array_test])\n",
    "y_predict = y_data_scaler.inverse_transform(y_predict_norm)\n",
    "y_data_test = y_data_scaler.inverse_transform(y_data_norm_array_test)\n",
    "for i in range(len(y_predict)):\n",
    "    y_predict[i][0] = round(y_predict[i][0])\n",
    "#print y_predict[0:20]\n",
    "#print y_data_test[0:20]\n",
    "print (\"Mean squared error on test set:\",mean_squared_error(y_predict, y_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492 5.0 28.0\n",
      "['13/04/2015', 88, 18, [62, 56, 50, 50, 47, 45, 89, 72, 55, 30.17, 30.09, 30.02, 10, 10, 7, 29, 15, 36, 0, 4, 1, 0, 0, 0, 0, 276]] [0.94069948 0.04336001 0.75       1.         0.         0.\n",
      " 0.         0.         0.         0.         0.         1.\n",
      " 0.         0.         0.60784314 0.68292683 0.66666667 0.73529412\n",
      " 0.734375   0.71428571 0.89       0.75       0.63953488 0.9898294\n",
      " 0.98947715 0.98880105 0.5        0.5        0.35       0.2265625\n",
      " 0.65217391 0.58064516 0.         0.5        1.         0.\n",
      " 0.         0.         0.         0.76666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "693 1.0 25.0\n",
      "['19/03/2015', 70, 16, [73, 60, 47, 52, 49, 43, 93, 64, 35, 30.08, 30.05, 30, 10, 10, 10, 18, 6, 21, 0, 2, 1, 0, 0, 0, 0, 294]] [0.94073527 0.04374775 0.5        0.         0.         0.\n",
      " 1.         0.         0.         0.         1.         0.\n",
      " 0.         0.         0.71568627 0.73170732 0.62666667 0.76470588\n",
      " 0.765625   0.68253968 0.93       0.66666667 0.40697674 0.98687664\n",
      " 0.98816179 0.98814229 0.5        0.5        0.5        0.140625\n",
      " 0.26086957 0.33870968 0.         0.25       1.         0.\n",
      " 0.         0.         0.         0.81666667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "4816 10.0 39.0\n",
      "['07/11/2014', 70, 16, [70, 60, 50, 58, 54, 48, 100, 81, 61, 30.24, 30.18, 30.1, 10, 5, 0, 13, 4, 15, 0.01, 3, 0, 0, 0, 0, 1, 332]] [0.94073527 0.04374775 0.5        0.         0.         0.\n",
      " 0.         1.         0.         0.         0.         0.\n",
      " 0.         1.         0.68627451 0.73170732 0.66666667 0.85294118\n",
      " 0.84375    0.76190476 1.         0.84375    0.70930233 0.99212598\n",
      " 0.9924367  0.9914361  0.5        0.25       0.         0.1015625\n",
      " 0.17391304 0.24193548 0.00297619 0.375      0.         0.\n",
      " 0.         0.         1.         0.92222222 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "10061 2.0 24.000000000000004\n",
      "['24/08/2015', 88, 16, [75, 68, 61, 57, 55, 54, 84, 69, 53, 30.06, 30.02, 29.97, 10, 10, 7, 17, 10, 22, 0, 4, 1, 0, 0, 0, 0, 281]] [0.94069948 0.04336001 0.75       1.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.73529412 0.82926829 0.81333333 0.83823529\n",
      " 0.859375   0.85714286 0.84       0.71875    0.61627907 0.98622047\n",
      " 0.98717527 0.98715415 0.5        0.5        0.35       0.1328125\n",
      " 0.43478261 0.35483871 0.         0.5        1.         0.\n",
      " 0.         0.         0.         0.78055556 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "13440 4.0 25.0\n",
      "['09/09/2014', 70, 16, [72, 65, 57, 56, 53, 52, 87, 72, 57, 30.01, 29.96, 29.91, 10, 10, 10, 17, 7, 21, 0, 5, 1, 0, 0, 0, 0, 270]] [0.94073527 0.04374775 0.5        0.         1.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.70588235 0.79268293 0.76       0.82352941\n",
      " 0.828125   0.82539683 0.87       0.75       0.6627907  0.98458005\n",
      " 0.98520224 0.98517787 0.5        0.5        0.5        0.1328125\n",
      " 0.30434783 0.33870968 0.         0.625      1.         0.\n",
      " 0.         0.         0.         0.75       0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "17840 4.0 28.0\n",
      "['03/10/2014', 70, 17, [89, 72, 55, 59, 49, 42, 72, 47, 21, 30.1, 30.04, 29.99, 10, 10, 10, 15, 5, 20, 0, 0, 1, 0, 0, 0, 0, 289]] [0.94073527 0.04374775 0.5        0.         0.         0.\n",
      " 0.         1.         0.         0.         0.         0.\n",
      " 0.         1.         0.87254902 0.87804878 0.73333333 0.86764706\n",
      " 0.765625   0.66666667 0.72       0.48958333 0.24418605 0.98753281\n",
      " 0.98783295 0.98781291 0.5        0.5        0.5        0.1171875\n",
      " 0.2173913  0.32258065 0.         0.         1.         0.\n",
      " 0.         0.         0.         0.80277778 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "18408 7.0 32.0\n",
      "['25/08/2015', 88, 17, [74, 67, 60, 57, 56, 54, 84, 69, 53, 30.03, 29.99, 29.94, 10, 9, 6, 18, 10, 23, 0, 4, 1, 0, 0, 0, 0, 290]] [0.94069948 0.04336001 0.75       0.         1.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.7254902  0.81707317 0.8        0.83823529\n",
      " 0.875      0.85714286 0.84       0.71875    0.61627907 0.98523622\n",
      " 0.98618875 0.98616601 0.5        0.45       0.3        0.140625\n",
      " 0.43478261 0.37096774 0.         0.5        1.         0.\n",
      " 0.         0.         0.         0.80555556 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "23248 4.0 25.0\n",
      "['29/10/2014', 69, 17, [77, 64, 50, 58, 53, 49, 89, 63, 36, 30.12, 30.06, 29.98, 10, 10, 10, 15, 4, 17, 0, 1, 1, 0, 0, 0, 0, 285]] [0.94023004 0.04225219 0.75       0.         0.         1.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         1.         0.75490196 0.7804878  0.66666667 0.85294118\n",
      " 0.828125   0.77777778 0.89       0.65625    0.41860465 0.98818898\n",
      " 0.98849063 0.98748353 0.5        0.5        0.5        0.1171875\n",
      " 0.17391304 0.27419355 0.         0.125      1.         0.\n",
      " 0.         0.         0.         0.79166667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "24925 2.0 26.0\n",
      "['30/10/2014', 70, 16, [71, 63, 54, 57, 53, 47, 84, 74, 63, 29.96, 29.92, 29.89, 10, 10, 10, 16, 6, 26, 0, 5, 1, 0, 0, 0, 0, 270]] [0.94073527 0.04374775 0.5        0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         1.         0.69607843 0.76829268 0.72       0.83823529\n",
      " 0.828125   0.74603175 0.84       0.77083333 0.73255814 0.98293963\n",
      " 0.98388688 0.9845191  0.5        0.5        0.5        0.125\n",
      " 0.26086957 0.41935484 0.         0.625      1.         0.\n",
      " 0.         0.         0.         0.75       0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "31298 13.0 47.0\n",
      "['12/08/2015', 88, 17, [78, 67, 55, 61, 57, 50, 93, 67, 41, 30.08, 30.03, 29.98, 10, 10, 10, 18, 9, 22, 0, 2, 1, 0, 0, 0, 0, 285]] [0.94069948 0.04336001 0.75       0.         0.         1.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.76470588 0.81707317 0.73333333 0.89705882\n",
      " 0.890625   0.79365079 0.93       0.69791667 0.47674419 0.98687664\n",
      " 0.98750411 0.98748353 0.5        0.5        0.5        0.140625\n",
      " 0.39130435 0.35483871 0.         0.25       1.         0.\n",
      " 0.         0.         0.         0.79166667 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "32474 7.0 32.0\n",
      "['27/05/2015', 88, 17, [63, 58, 53, 50, 49, 48, 89, 75, 60, 30.04, 30.02, 30, 10, 10, 10, 21, 12, 24, 0, 6, 1, 0, 0, 0, 0, 269]] [0.94069948 0.04336001 0.75       0.         0.         1.\n",
      " 0.         0.         0.         0.         0.         1.\n",
      " 0.         0.         0.61764706 0.70731707 0.70666667 0.73529412\n",
      " 0.765625   0.76190476 0.89       0.78125    0.69767442 0.9855643\n",
      " 0.98717527 0.98814229 0.5        0.5        0.5        0.1640625\n",
      " 0.52173913 0.38709677 0.         0.75       1.         0.\n",
      " 0.         0.         0.         0.74722222 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "35899 5.0 36.0\n",
      "['02/10/2014', 70, 17, [87, 70, 52, 61, 48, 42, 72, 51, 29, 30.04, 29.99, 29.94, 10, 10, 9, 14, 6, 18, 0, 0, 1, 0, 0, 0, 0, 309]] [0.94073527 0.04374775 0.5        0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         1.         0.85294118 0.85365854 0.69333333 0.89705882\n",
      " 0.75       0.66666667 0.72       0.53125    0.3372093  0.9855643\n",
      " 0.98618875 0.98616601 0.5        0.5        0.45       0.109375\n",
      " 0.26086957 0.29032258 0.         0.         1.         0.\n",
      " 0.         0.         0.         0.85833333 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Error analysis\n",
    "Report some cases with high error\"\"\"\n",
    "for i in range(len(y_predict)):\n",
    "    if abs(y_predict[i][0]-y_data_test[i][0]) > 20:\n",
    "        print i, y_predict[i][0],y_data_test[i][0]\n",
    "        print full_data_test[i], station_data_norm_array_test[i]\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
